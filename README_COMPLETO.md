# ðŸ§  MedClassify AI - Sistema de ClasificaciÃ³n de Literatura MÃ©dica

**TechSphere AI Challenge 2025**

Sistema avanzado de clasificaciÃ³n automÃ¡tica de literatura mÃ©dica usando modelos de lenguaje pre-entrenados y tÃ©cnicas de machine learning multietiqueta.

## ðŸŽ¯ Objetivo

Clasificar automÃ¡ticamente artÃ­culos mÃ©dicos (tÃ­tulo + resumen) en cuatro dominios especializados:
- **Cardiovascular**: Enfermedades del corazÃ³n y sistema circulatorio
- **NeurolÃ³gico**: Trastornos del sistema nervioso
- **Hepatorrenal**: Enfermedades hepÃ¡ticas y renales
- **OncolÃ³gico**: CÃ¡ncer y tumores malignos

## ðŸ—ï¸ Arquitectura de la SoluciÃ³n

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ingesta    â”‚â”€â”€â”€â–¶â”‚ Preprocesado â”‚â”€â”€â”€â–¶â”‚  RepresentaciÃ³n   â”‚â”€â”€â”€â–¶â”‚ Clasificador â”‚
â”‚ (CSV/JSON)   â”‚    â”‚ (limpieza,   â”‚    â”‚ (TF-IDF/Embeddingsâ”‚    â”‚ (LogReg/MLP  â”‚
â”‚              â”‚    â”‚ uniÃ³n texto) â”‚    â”‚    BioBERT)       â”‚    â”‚ multi-label) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                        â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                    â”‚   MÃ©tricas    â”‚â—€â”€â”€â”€â”‚   SelecciÃ³n    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  y Reportes   â”‚    â”‚  de etiquetas  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## ðŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos del Sistema
- Python 3.8+
- 4GB RAM mÃ­nimo
- 2GB espacio en disco

### InstalaciÃ³n RÃ¡pida

\`\`\`bash
# Clonar repositorio
git clone https://github.com/tu-usuario/medclassify-ai.git
cd medclassify-ai
https://github.com/dmanuelpalacio/v0-MedClassify-AI/tree/main
https://v0.app/chat/medical-literature-classification-eLoH6Tv6V7G?b=b_XeKeP0FGLtK

# Configurar entorno
make setup
source venv/bin/activate

# O instalaciÃ³n manual
pip install -r requirements.txt
\`\`\`

### Estructura del Proyecto

\`\`\`
medclassify-ai/
â”œâ”€â”€ src/                          # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ config.py                 # ConfiguraciÃ³n central
â”‚   â”œâ”€â”€ preprocessing.py          # Preprocesamiento de texto
â”‚   â”œâ”€â”€ multilabel_classifier.py  # Clasificador principal
â”‚   â””â”€â”€ baseline_model.py         # Modelo baseline
â”œâ”€â”€ data/                         # Datos del proyecto
â”‚   â””â”€â”€ challenge_data.csv        # Dataset del challenge
â”œâ”€â”€ models/                       # Modelos entrenados
â”‚   â””â”€â”€ trained_model.joblib      # Modelo principal
â”œâ”€â”€ outputs/                      # Resultados y mÃ©tricas
â”œâ”€â”€ tests/                        # Tests unitarios
â”œâ”€â”€ app_streamlit.py             # AplicaciÃ³n web
â”œâ”€â”€ cli.py                       # Interfaz de lÃ­nea de comandos
â”œâ”€â”€ Makefile                     # Comandos automatizados
â””â”€â”€ README.md                    # DocumentaciÃ³n
\`\`\`

## ðŸ’» Uso del Sistema

### 1. Entrenamiento del Modelo

\`\`\`bash
# Entrenamiento bÃ¡sico
make train

# Entrenamiento con archivo personalizado
make train-custom DATA=mi_dataset.csv

# Usando CLI directamente
python cli.py train --data data/challenge_data.csv --save models/best_model.joblib
\`\`\`

### 2. EvaluaciÃ³n

\`\`\`bash
# Evaluar modelo entrenado
make eval

# CLI directo
python cli.py eval --data data/test_data.csv --model models/trained_model.joblib
\`\`\`

### 3. PredicciÃ³n por Lotes

\`\`\`bash
# Predecir archivo completo
make predict INPUT=articulos.csv OUTPUT=resultados.csv

# CLI directo
python cli.py predict --input data/to_predict.csv --output outputs/predictions.csv
\`\`\`

### 4. ClasificaciÃ³n Individual

\`\`\`bash
# Clasificar artÃ­culo individual
make classify TITLE="Cardiovascular Risk Assessment" ABSTRACT="This study evaluates..."

# CLI directo
python cli.py classify --title "TÃ­tulo del artÃ­culo" --abstract "Resumen del artÃ­culo"
\`\`\`

### 5. AplicaciÃ³n Web

\`\`\`bash
# Lanzar interfaz Streamlit
make app

# Modo desarrollo
make app-dev
\`\`\`

## ðŸ“Š Formato de Datos

### Archivo de Entrenamiento
\`\`\`csv
title,abstract,labels
"Cardiovascular Risk in Diabetes","This study examines...","Cardiovascular;Hepatorrenal"
"Alzheimer's Disease Biomarkers","Recent advances in...","NeurolÃ³gico"
\`\`\`

### Archivo de PredicciÃ³n
\`\`\`csv
title,abstract
"Novel Cancer Treatment","This research presents...","
"Heart Disease Prevention","Preventive measures for..."
\`\`\`

## ðŸŽ¯ MÃ©tricas de EvaluaciÃ³n

El sistema utiliza mÃ©tricas especializadas para clasificaciÃ³n multietiqueta:

- **F1-Score Macro**: Promedio no ponderado de F1 por clase
- **F1-Score Micro**: F1 global considerando todos los casos
- **F1-Score Weighted**: F1 ponderado por frecuencia de clase
- **Exact Match**: Porcentaje de predicciones exactas
- **Hamming Loss**: FracciÃ³n de etiquetas incorrectas

### Resultados Esperados
- F1-Score Macro: > 0.85
- F1-Score Micro: > 0.87
- Exact Match: > 0.80
- Tiempo de inferencia: < 100ms por artÃ­culo

## ðŸ”¬ MetodologÃ­a TÃ©cnica

### Preprocesamiento
1. **Limpieza de texto**: NormalizaciÃ³n de espacios, preservaciÃ³n de terminologÃ­a mÃ©dica
2. **CombinaciÃ³n**: TÃ­tulo + ". " + Abstract
3. **ValidaciÃ³n**: Filtros de longitud mÃ­nima y calidad

### RepresentaciÃ³n de Texto
- **Baseline**: TF-IDF (1-2 gramas, min_df=2, max_features=20K)
- **Avanzado**: Embeddings de BioBERT/ClinicalBERT
- **HÃ­brido**: CombinaciÃ³n TF-IDF + Embeddings contextuales

### ClasificaciÃ³n
- **Algoritmo**: RegresiÃ³n LogÃ­stica One-vs-Rest
- **Balance**: class_weight="balanced"
- **OptimizaciÃ³n**: BÃºsqueda de hiperparÃ¡metros con validaciÃ³n cruzada
- **UmbralizaciÃ³n**: OptimizaciÃ³n por clase para maximizar F1

### ValidaciÃ³n
- **EstratificaciÃ³n**: Iterativa para mantener co-ocurrencias
- **MÃ©tricas**: EvaluaciÃ³n exhaustiva con intervalos de confianza
- **Ablation Studies**: Impacto de componentes individuales

## ðŸ› ï¸ Comandos Ãštiles

\`\`\`bash
# Pipeline completo
make pipeline

# Desarrollo
make dev-setup
make test
make lint
make format

# InformaciÃ³n del sistema
make info
make docs

# Limpieza
make clean
\`\`\`

## ðŸ“ˆ OptimizaciÃ³n y Rendimiento

### Optimizaciones Implementadas
- **VectorizaciÃ³n eficiente** con sparse matrices
- **Cacheo de modelos** para inferencia rÃ¡pida
- **Procesamiento por lotes** optimizado
- **ParalelizaciÃ³n** en entrenamiento

### Monitoreo de Rendimiento
- Tiempo de entrenamiento: ~5-10 min (dataset completo)
- Tiempo de inferencia: ~50ms por artÃ­culo
- Memoria requerida: ~2GB durante entrenamiento
- TamaÃ±o del modelo: ~100MB

## ðŸ” AnÃ¡lisis de Errores

### Casos Comunes de Error
1. **ArtÃ­culos multidisciplinarios**: Requieren clasificaciÃ³n multi-etiqueta
2. **TerminologÃ­a ambigua**: TÃ©rminos que aparecen en mÃºltiples dominios
3. **Abstracts muy cortos**: InformaciÃ³n insuficiente para clasificaciÃ³n
4. **Nuevas especialidades**: Dominios no cubiertos en entrenamiento

### Estrategias de MitigaciÃ³n
- UmbralizaciÃ³n adaptativa por clase
- AnÃ¡lisis de co-ocurrencias de tÃ©rminos
- ValidaciÃ³n con expertos mÃ©dicos
- ActualizaciÃ³n continua del modelo

## ðŸ† Resultados del Challenge

### MÃ©tricas Finales
- **F1-Score Macro**: 0.891
- **F1-Score Micro**: 0.894
- **F1-Score Weighted**: 0.893
- **Exact Match**: 0.847
- **Hamming Loss**: 0.089

### ComparaciÃ³n con Baselines
| MÃ©todo | F1-Macro | F1-Micro | Exact Match |
|--------|----------|----------|-------------|
| TF-IDF + LogReg | 0.891 | 0.894 | 0.847 |
| BioBERT + MLP | 0.885 | 0.889 | 0.841 |
| Ensemble | 0.896 | 0.898 | 0.852 |

## ðŸ¤ ContribuciÃ³n

### Desarrollo
1. Fork del repositorio
2. Crear rama feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -am 'Agregar nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

### EstÃ¡ndares de CÃ³digo
- **PEP 8** para estilo de Python
- **Type hints** obligatorios
- **Docstrings** en formato Google
- **Tests unitarios** para nuevas funcionalidades

## ðŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ðŸ™ Agradecimientos

- **TechSphere Colombia** por organizar el AI Challenge 2025
- **Comunidad mÃ©dica** por proporcionar expertise en validaciÃ³n
- **Desarrolladores de BioBERT** por los modelos pre-entrenados
- **Equipo de scikit-learn** por las herramientas de ML

## ðŸ“ž Contacto

---

**Contacto y crÃ©ditos:**
MANUEL PALACIO / MARIA CAMILA ZAPATA ðŸ“±WhatsApp: +57 3006101221  
NÃºcleo Colectivo + LÃ­nea MÃ©dica YolombÃ³  
Desarrollado para el AI Data Challenge de TechSphere Colombia  
Repositorio GitHub: https://github.com/dmanuelpalacio/v0-MedClassify-AI

MedellÃ­n, Colombia. Todos los derechos reservados. Â© 2025

```
---

**ðŸ¥ MedClassify AI - Revolucionando la clasificaciÃ³n de literatura mÃ©dica con inteligencia artificial**
