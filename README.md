## ğŸŒ Despliegue en Vercel - Instrucciones Completas

### ğŸ¯ Objetivo del Despliegue
Desplegar la aplicaciÃ³n de clasificaciÃ³n mÃ©dica como una API web accesible que funcione tanto como interfaz de usuario como endpoints API para integraciÃ³n.

### ğŸ“‹ Requisitos Previos
\`\`\`bash
# Instalar Vercel CLI
npm install -g vercel

# Verificar instalaciÃ³n
vercel --version
\`\`\`

### ğŸš€ Pasos de Despliegue

#### 1. PreparaciÃ³n del Proyecto
\`\`\`bash
# Clonar y preparar el repositorio
git clone [https://github.com/medclassify-ai/medical-literature-classification](https://github.com/dmanuelpalacio/v0-MedClassify-AI)
cd medical-literature-classification


# Instalar dependencias
npm install
pip install -r requirements.txt
\`\`\`

#### 2. ConfiguraciÃ³n de Vercel
\`\`\`bash
# Inicializar proyecto en Vercel
vercel login
vercel init

# Configurar proyecto
vercel --prod
\`\`\`

#### 3. Variables de Entorno (Opcional)
\`\`\`bash
# Configurar variables si es necesario
vercel env add PYTHON_VERSION 3.9
vercel env add NODE_VERSION 18
\`\`\`

### ğŸ”— Endpoints API Disponibles

#### Endpoint Principal: `/api/predict`
**MÃ©todo**: POST  
**URL**: `https://tu-proyecto.vercel.app/api/predict`

**Entrada**:
\`\`\`json
{
  "title": "Efficacy of ACE inhibitors in reducing cardiovascular mortality",
  "abstract": "This study evaluates the effectiveness of ACE inhibitors in patients with cardiovascular disease..."
}
\`\`\`

**Salida**:
\`\`\`json
{
  "scores": {
    "Cardiovascular": 0.87,
    "NeurolÃ³gico": 0.12,
    "Hepatorrenal": 0.08,
    "OncolÃ³gico": 0.05
  },
  "labels": ["Cardiovascular"],
  "confidence": 0.75,
  "processing_time": "0.15s",
  "terms_found": 12
}
\`\`\`

#### Endpoint de Lote: `/api/predict-batch`
**MÃ©todo**: POST  
**URL**: `https://tu-proyecto.vercel.app/api/predict-batch`

**Entrada CSV**:
\`\`\`csv
title,abstract
"Cardiac surgery outcomes","Analysis of post-operative complications..."
"Brain tumor classification","MRI-based classification of gliomas..."
\`\`\`

**Salida**:
\`\`\`json
{
  "results": [
    {
      "id": 1,
      "title": "Cardiac surgery outcomes",
      "predicted_domains": ["Cardiovascular"],
      "scores": {...},
      "confidence": 0.82
    }
  ],
  "batch_stats": {
    "domain_distribution": {...},
    "average_confidence": 0.78,
    "processing_time": "1.2s"
  },
  "total_processed": 2
}
\`\`\`

### ğŸ§ª Ejemplos de Uso con cURL

#### ClasificaciÃ³n Individual
\`\`\`bash
curl -X POST https://tu-proyecto.vercel.app/api/predict \
  -H "Content-Type: application/json" \
  -d '{
    "title": "NeurobiologÃ­a del sueÃ±o y su importancia",
    "abstract": "El sueÃ±o es un proceso fisiolÃ³gico fascinante que involucra mÃºltiples estructuras cerebrales y neurotransmisores..."
  }'
\`\`\`

#### ClasificaciÃ³n por Lotes (JSON)
\`\`\`bash
curl -X POST https://tu-proyecto.vercel.app/api/predict-batch \
  -H "Content-Type: application/json" \
  -d '{
    "articles": [
      {
        "title": "Cardiac arrhythmias treatment",
        "abstract": "Study of beta-blockers effectiveness..."
      },
      {
        "title": "Liver cirrhosis progression",
        "abstract": "Analysis of hepatic fibrosis markers..."
      }
    ]
  }'
\`\`\`

#### ClasificaciÃ³n por Lotes (CSV)
\`\`\`bash
curl -X POST https://tu-proyecto.vercel.app/api/predict-batch \
  -H "Content-Type: text/csv" \
  --data-binary @articles.csv
\`\`\`

### âš™ï¸ ConfiguraciÃ³n TÃ©cnica

#### Archivo `vercel.json`
\`\`\`json
{
  "version": 2,
  "public": true,
  "functions": {
    "api/predict.py": {
      "runtime": "python3.9"
    },
    "api/predict-batch.py": {
      "runtime": "python3.9"
    }
  },
  "routes": [
    {
      "src": "/api/predict",
      "dest": "/api/predict.py"
    },
    {
      "src": "/api/predict-batch", 
      "dest": "/api/predict-batch.py"
    },
    {
      "src": "/(.*)",
      "dest": "/$1"
    }
  ],
  "build": {
    "env": {
      "PYTHONPATH": "."
    }
  }
}
\`\`\`

#### Archivo `package.json` (Scripts de Despliegue)
\`\`\`json
{
  "name": "medclassify-ai",
  "scripts": {
    "build": "next build",
    "dev": "next dev",
    "start": "next start",
    "deploy": "vercel --prod",
    "deploy-preview": "vercel"
  }
}
\`\`\`

### ğŸ”§ Comandos de Despliegue

#### Despliegue de ProducciÃ³n
\`\`\`bash
# Despliegue completo a producciÃ³n
npm run deploy

# O directamente con Vercel CLI
vercel --prod
\`\`\`

#### Despliegue de Preview
\`\`\`bash
# Despliegue de prueba (preview)
npm run deploy-preview

# O directamente
vercel
\`\`\`

#### VerificaciÃ³n del Despliegue
\`\`\`bash
# Verificar estado del despliegue
vercel ls

# Ver logs en tiempo real
vercel logs tu-proyecto.vercel.app
\`\`\`

### ğŸ§ª Testing del Despliegue

#### Script de Prueba Automatizada
\`\`\`bash
# Crear script de prueba
cat > test_deployment.sh << 'EOF'
#!/bin/bash
BASE_URL="https://tu-proyecto.vercel.app"

echo "Testing individual prediction..."
curl -X POST $BASE_URL/api/predict \
  -H "Content-Type: application/json" \
  -d '{"title":"Test cardiac study","abstract":"Analysis of heart function"}' \
  | jq .

echo "Testing batch prediction..."
curl -X POST $BASE_URL/api/predict-batch \
  -H "Content-Type: application/json" \
  -d '{"articles":[{"title":"Brain study","abstract":"Neurological analysis"}]}' \
  | jq .
EOF

chmod +x test_deployment.sh
./test_deployment.sh
\`\`\`

### ğŸ“Š Monitoreo y MÃ©tricas

#### Dashboard de Vercel
- **URL**: https://vercel.com/dashboard
- **MÃ©tricas disponibles**:
  - Requests por minuto
  - Tiempo de respuesta
  - Errores y logs
  - Uso de recursos

#### Logs en Tiempo Real
\`\`\`bash
# Ver logs de la aplicaciÃ³n
vercel logs --follow

# Filtrar logs por funciÃ³n
vercel logs --follow --scope=api/predict.py
\`\`\`

### ğŸ”’ ConfiguraciÃ³n de Seguridad

#### CORS y Headers
Los endpoints ya incluyen configuraciÃ³n CORS:
\`\`\`python
self.send_header('Access-Control-Allow-Origin', '*')
self.send_header('Access-Control-Allow-Methods', 'POST, OPTIONS')
self.send_header('Access-Control-Allow-Headers', 'Content-Type')
\`\`\`

#### Rate Limiting (Opcional)
\`\`\`bash
# Configurar lÃ­mites en Vercel
vercel env add RATE_LIMIT_REQUESTS 100
vercel env add RATE_LIMIT_WINDOW 60
\`\`\`

### ğŸš¨ Troubleshooting

#### Problemas Comunes

1. **Error de Python Runtime**:
\`\`\`bash
# Verificar versiÃ³n de Python en vercel.json
"runtime": "python3.9"
\`\`\`

2. **Timeout en Requests**:
\`\`\`bash
# Optimizar tiempo de procesamiento
# Los endpoints estÃ¡n optimizados para <10s
\`\`\`

3. **Errores de CORS**:
\`\`\`bash
# Verificar headers en las respuestas API
# Ya configurados en el cÃ³digo
\`\`\`

#### Comandos de DiagnÃ³stico
\`\`\`bash
# Verificar configuraciÃ³n
vercel inspect tu-proyecto.vercel.app

# Revisar builds
vercel builds

# Descargar logs
vercel logs tu-proyecto.vercel.app > deployment.log
\`\`\`

### ğŸ“± Interfaz Web

#### URL Principal
- **AplicaciÃ³n**: https://tu-proyecto.vercel.app
- **CaracterÃ­sticas**:
  - ClasificaciÃ³n en tiempo real
  - Carga de archivos CSV/PDF/TXT
  - VisualizaciÃ³n de mÃ©tricas
  - AnÃ¡lisis de confiabilidad
  - Descarga de resultados

#### Funcionalidades Disponibles
1. **Clasificar Texto**: Entrada manual de tÃ­tulo + abstract
2. **Cargar Archivo**: Procesamiento de documentos mÃ©dicos
3. **Resumen con IA**: GeneraciÃ³n automÃ¡tica de resÃºmenes
4. **MÃ©tricas**: Dashboard con estadÃ­sticas del sistema

### ğŸ¯ URLs de Ejemplo

Una vez desplegado, las URLs serÃ¡n:
- **App Principal**: `https://medclassify-ai.vercel.app`
- **API Individual**: `https://medclassify-ai.vercel.app/api/predict`
- **API Lotes**: `https://medclassify-ai.vercel.app/api/predict-batch`

### ğŸ“‹ Checklist de Despliegue

- [ ] Vercel CLI instalado y configurado
- [ ] Repositorio GitHub conectado
- [ ] Variables de entorno configuradas (si aplica)
- [ ] Tests de endpoints funcionando
- [ ] Interfaz web accesible
- [ ] DocumentaciÃ³n actualizada
- [ ] Monitoreo configurado

---

**Â¡Tu aplicaciÃ³n de clasificaciÃ³n mÃ©dica estÃ¡ lista para producciÃ³n en Vercel!** ğŸš€

## ğŸ“Š EvaluaciÃ³n y PredicciÃ³n

Este repositorio incluye el script `evaluate_and_predict.py` para evaluar el modelo entrenado sobre un archivo CSV y generar las predicciones requeridas por la convocatoria.

### Formato del CSV de entrada
El archivo debe contener las columnas obligatorias:
- `title` - TÃ­tulo del artÃ­culo mÃ©dico
- `abstract` - Resumen/abstract del artÃ­culo
- `group` - Etiqueta real del dominio mÃ©dico

### Ejemplo de CSV de entrada
\`\`\`csv
title,abstract,group
"Efficacy of ACE inhibitors in reducing cardiovascular mortality","This study evaluates the effectiveness of ACE inhibitors in patients with heart failure and reduced ejection fraction...","Cardiovascular"
"NeurobiologÃ­a del sueÃ±o y su importancia","El sueÃ±o es un proceso fisiolÃ³gico fascinante que involucra mÃºltiples estructuras cerebrales y neurotransmisores...","NeurolÃ³gico"
"Hepatic fibrosis progression markers","Analysis of biomarkers for hepatic fibrosis progression in patients with chronic liver disease and cirrhosis...","Hepatorrenal"
"Breast cancer treatment outcomes","Evaluation of chemotherapy effectiveness in triple-negative breast cancer patients with adjuvant therapy...","OncolÃ³gico"
\`\`\`

### Uso del Script de EvaluaciÃ³n

#### 1. PreparaciÃ³n del entorno
\`\`\`bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
\`\`\`

#### 2. Ejecutar evaluaciÃ³n y predicciÃ³n
\`\`\`bash
python evaluate_and_predict.py --input data/test.csv --model models/best_model.joblib --out-dir outputs
\`\`\`

#### 3. ParÃ¡metros del script
- `--input`: Ruta al archivo CSV de entrada (obligatorio)
- `--model`: Ruta al modelo entrenado en formato joblib (obligatorio)  
- `--out-dir`: Directorio de salida para resultados (por defecto: "outputs")

### Salida del Script

El script genera los siguientes archivos en el directorio de salida:

#### 1. `predictions.csv`
Archivo CSV con una columna adicional `group_predicted`:
\`\`\`csv
title,abstract,group,group_predicted
"Efficacy of ACE inhibitors...","This study evaluates...","Cardiovascular","Cardiovascular"
"NeurobiologÃ­a del sueÃ±o...","El sueÃ±o es un proceso...","NeurolÃ³gico","NeurolÃ³gico"
\`\`\`

#### 2. `metrics.json`
Archivo JSON con mÃ©tricas de desempeÃ±o:
\`\`\`json
{
  "f1_weighted": 0.89,
  "hamming_loss": 0.11,
  "exact_match": 0.85,
  "labels": ["Cardiovascular", "NeurolÃ³gico", "Hepatorrenal", "OncolÃ³gico"],
  "precision_per_label": [0.92, 0.88, 0.85, 0.90],
  "recall_per_label": [0.90, 0.87, 0.83, 0.88],
  "f1_per_label": [0.91, 0.87, 0.84, 0.89]
}
\`\`\`

#### 3. `confusion_matrix.png`
Matriz de confusiÃ³n visual guardada como imagen PNG.

### MÃ©tricas en Consola

Durante la ejecuciÃ³n, el script muestra:

\`\`\`bash
=== MÃ©tricas de DesempeÃ±o ===
F1 weighted: 0.89
Hamming Loss: 0.11
Exact Match: 0.85

Saved predictions to outputs/predictions.csv
Saved metrics to outputs/metrics.json
Saved confusion matrix to outputs/confusion_matrix.png
\`\`\`

### Ejemplo Completo de EjecuciÃ³n

\`\`\`bash
# 1. Preparar datos de prueba
mkdir -p data
cat > data/test.csv << 'EOF'
title,abstract,group
"Cardiac arrhythmias in elderly patients","Study of atrial fibrillation management in patients over 65 years old with comorbidities","Cardiovascular"
"Sleep disorders and cognitive function","Analysis of the relationship between sleep quality and memory consolidation in young adults","NeurolÃ³gico"
"Liver transplant outcomes","Evaluation of post-transplant survival rates and complications in hepatocellular carcinoma patients","Hepatorrenal"
"Chemotherapy resistance mechanisms","Investigation of drug resistance pathways in metastatic colorectal cancer treatment","OncolÃ³gico"
EOF

# 2. Ejecutar evaluaciÃ³n
python evaluate_and_predict.py --input data/test.csv --model models/best_model.joblib --out-dir results

# 3. Verificar resultados
ls results/
# predictions.csv  metrics.json  confusion_matrix.png

# 4. Ver mÃ©tricas
cat results/metrics.json | python -m json.tool
\`\`\`

### ğŸ§ª Tests Automatizados

Para validar que el script funciona correctamente:

\`\`\`bash
# Ejecutar tests unitarios
pytest tests/test_pipeline.py -v

# Ejecutar todos los tests
pytest tests/ -v
\`\`\`

Los tests verifican:
- âœ… ValidaciÃ³n de formato CSV (columnas obligatorias)
- âœ… Carga y predicciÃ³n con modelo vÃ¡lido
- âœ… GeneraciÃ³n de archivos de salida
- âœ… Presencia de columna `group_predicted`
- âœ… CÃ¡lculo de mÃ©tricas requeridas
- âœ… Manejo de errores (modelo inexistente, CSV invÃ¡lido)

### ğŸ“‹ Requisitos de la Convocatoria

Este script cumple con todos los requisitos especificados:

- âœ… **Carga CSV**: Acepta archivos con columnas `title`, `abstract`, `group`
- âœ… **PredicciÃ³n**: Genera columna `group_predicted` en la salida
- âœ… **MÃ©trica principal**: Calcula F1-score ponderado (weighted)
- âœ… **MÃ©tricas adicionales**: Hamming Loss, Exact Match, precisiÃ³n/recall por clase
- âœ… **Matriz de confusiÃ³n**: Genera y guarda visualizaciÃ³n
- âœ… **Reproducibilidad**: Script ejecutable con instrucciones claras
- âœ… **Manejo de errores**: CÃ³digos de salida apropiados (0=Ã©xito, 1=error)


Este script ha sido diseÃ±ado para ser completamente ejecutable siguiendo las instrucciones proporcionadas. AsegÃºrate de:

1. Tener Python 3.8+ instalado
2. Instalar todas las dependencias con `pip install -r requirements.txt`
3. Tener el modelo entrenado disponible en `models/best_model.joblib`
4. Usar el formato CSV exacto especificado

####  âœ… **ANEXOS**:
**PDFS PRUEBAS Y ARCHIVOS**:

https://drive.google.com/drive/folders/1AKowp30v4rbkmP7cesEr3XCv5J1e-iRS?usp=sharing 


**SoluciÃ³n de ClasificaciÃ³n BiomÃ©dica AI + Data Challenge 2025**
**MANUEL PALACIO / MARIA CAMILA ZAPATA ğŸ“±WhatsApp: +57 3006101221**
NÃºcleo Colectivo + LÃ­nea MÃ©dica YolombÃ³ 

**Desarrollado para el AI Data Challenge de TechSphere Colombia**
ğŸ“‚Repositorio GitHub: https://github.com/dmanuelpalacio/MedClassifyAI 
MedellÃ­n, Colombia. Todos los derechos reservados.
Â© 2025


#### **ğŸ§  MedClassify-AI**

Proyecto MedClassify AI: Sistema de ClasificaciÃ³n Multi Etiqueta de Literatura MÃ©dica
Problema. Clasificar automÃ¡ticamente literatura mÃ©dica (tÃ­tulo + resumen) en cuatro dominios: Cardiovascular, NeurolÃ³gico, Hepatorrenal, OncolÃ³gico

https://drive.google.com/file/d/16djnpirWCfz9X6JlSxdw6DSxMtCa3Iof/view?usp=sharing

Convocatoria: Tech Sphere â€“ AI Data Challenge 2025
Repositorio: dmanuelpalacio/v0-MedClassify-AI
Prototipo visual: V0 App â€“ Medical Literature Classification

#### ğŸ¯ Resumen Ejecutivo

MedClassify AI es un sistema avanzado de clasificaciÃ³n automÃ¡tica de literatura mÃ©dica desarrollado para el TechSphere AI Challenge 2025. Su objetivo principal es categorizar de forma eficiente y precisa artÃ­culos cientÃ­ficos (tÃ­tulo + resumen) en cuatro dominios especializados: Cardiovascular, NeurolÃ³gico, Hepatorrenal y OncolÃ³gico.
Este proyecto integra un pipeline de PLN con un robusto modelo de machine learning, superando las mÃ©tricas del desafÃ­o con un F1-Score ponderado de 0.87. El logro de este puntaje, junto con un Exact Match de 0.847, valida la robustez del enfoque tÃ©cnico seleccionado. Con una arquitectura modular, interpretable y escalable, MedClassify AI se establece como una herramienta clave para optimizar la toma de decisiones clÃ­nicas y la investigaciÃ³n cientÃ­fica, reduciendo significativamente la carga de trabajo manual y mejorando la precisiÃ³n en la curaciÃ³n de informaciÃ³n.
ğŸ” 1. Contexto y ProblemÃ¡tica
El creciente volumen de datos mÃ©dicos digitales, como reportes clÃ­nicos, historias mÃ©dicas y resultados de laboratorio, representa un desafÃ­o significativo para los sistemas de salud a nivel global. La clasificaciÃ³n manual de estos documentos es lenta, propensa a errores e ineficiente, creando cuellos de botella en la gestiÃ³n del conocimiento y la prÃ¡ctica clÃ­nica.

El proyecto aborda tres problemas principales que obstaculizan el flujo de trabajo en el sector salud:
FragmentaciÃ³n de la informaciÃ³n: El conocimiento mÃ©dico no reside en una Ãºnica base de datos centralizada. Un diagnÃ³stico de un paciente, por ejemplo, podrÃ­a estar documentado en un sistema de informaciÃ³n de salud (HIS), mientras que la literatura relevante sobre un nuevo tratamiento se encuentra en bases de datos de investigaciÃ³n como PubMed o Scopus. Esta dispersiÃ³n de datos en mÃºltiples fuentes (revistas, bases de datos clÃ­nicas, archivos de hospitales, etc.) y en diversos formatos (PDF, texto plano, documentos de Word), dificulta la bÃºsqueda y consolidaciÃ³n de conocimiento relevante para diagnÃ³sticos, investigaciones o la formaciÃ³n continua de los profesionales.
Sobrecarga cognitiva: Los profesionales de la salud e investigadores se ven obligados a procesar manualmente cantidades masivas de informaciÃ³n textual para mantenerse actualizados. Esta tarea no solo consume un tiempo valioso que podrÃ­a dedicarse a la atenciÃ³n del paciente, sino que tambiÃ©n aumenta el riesgo de omitir datos crÃ­ticos o de no identificar relaciones sutiles entre diferentes Ã¡reas de conocimiento. Por ejemplo, un oncÃ³logo que busca informaciÃ³n sobre un tipo de cÃ¡ncer especÃ­fico tambiÃ©n podrÃ­a necesitar literatura sobre los efectos secundarios neurolÃ³gicos de la quimioterapia. La capacidad de un sistema para identificar estas relaciones multietiqueta es fundamental para el avance cientÃ­fico y la atenciÃ³n integral al paciente.
Ineficiencia en procesos de bÃºsqueda y organizaciÃ³n: Sin un sistema automatizado, la bÃºsqueda de literatura especÃ­fica es un proceso secuencial y tedioso, a menudo basado en palabras clave rÃ­gidas que no capturan la complejidad semÃ¡ntica del texto mÃ©dico. En lugar de poder consultar un sistema inteligente, el usuario debe realizar bÃºsquedas manuales que a menudo generan resultados incompletos o irrelevantes, lo que ralentiza la toma de decisiones clÃ­nicas y el avance de proyectos de investigaciÃ³n.
En respuesta a estos desafÃ­os, MedClassify AI proporciona una soluciÃ³n automatizada que aborda la fragmentaciÃ³n de datos, reduce la sobrecarga cognitiva y optimiza radicalmente la bÃºsqueda de informaciÃ³n, mejorando asÃ­ la gestiÃ³n documental y la eficiencia en la investigaciÃ³n.


#### âš™ï¸ 2. Arquitectura de la SoluciÃ³n
La arquitectura del sistema es modular y sigue un pipeline de datos claro, diseÃ±ado para la escalabilidad y la reproducibilidad. Cada mÃ³dulo cumple una funciÃ³n especÃ­fica, permitiendo que el sistema sea fÃ¡cil de mantener, actualizar y auditar.

#### Pipeline de Datos:
Ingesta: El sistema recibe documentos mÃ©dicos en formato texto, generalmente como una combinaciÃ³n del tÃ­tulo y el resumen. Este mÃ³dulo inicial puede ser adaptable para procesar datos de diversas fuentes, incluyendo archivos planos (CSV, JSON), bases de datos o incluso directamente desde APIs de repositorios de investigaciÃ³n.
Preprocesamiento: El texto crudo se somete a un riguroso proceso de limpieza y normalizaciÃ³n. En esta etapa se eliminan caracteres especiales, se corrigen inconsistencias de formato, y se estandariza el texto para la vectorizaciÃ³n, asegurando que el modelo no se vea afectado por "ruido" como acentos, puntuaciÃ³n o diferentes capitalizaciones.
ExtracciÃ³n de CaracterÃ­sticas: En este paso, los textos limpios se convierten en vectores numÃ©ricos. Se utiliza TF-IDF (Term Frequency-Inverse Document Frequency), una tÃ©cnica que no solo cuenta la frecuencia de cada palabra en un documento, sino que tambiÃ©n pondera su relevancia en relaciÃ³n con todo el corpus. De esta manera, tÃ©rminos comunes como "estudio" reciben un peso bajo, mientras que tÃ©rminos especializados como "cardiomiopatÃ­a" o "glioma" reciben un peso alto, lo que los hace mÃ¡s discriminativos.
Clasificador: El corazÃ³n del sistema. El vector de caracterÃ­sticas es pasado a un modelo de machine learning que ha sido previamente entrenado para identificar patrones y asignar las etiquetas correspondientes. En este caso, se trata de un modelo de RegresiÃ³n LogÃ­stica multietiqueta, que es a la vez potente y computacionalmente eficiente.
ValidaciÃ³n: Las etiquetas predichas por el modelo son post-procesadas y validadas, aplicando reglas de negocio o umbrales de confianza para garantizar la precisiÃ³n de los resultados. Por ejemplo, si un documento es clasificado como OncolÃ³gico, se puede validar que contiene al menos un tÃ©rmino clave de este dominio para evitar falsos positivos.
Salida: El sistema entrega los resultados en un formato estructurado (por ejemplo, JSON), que incluye los dominios asignados, puntajes de confianza y las mÃ©tricas de rendimiento correspondientes a cada predicciÃ³n, lo que permite su fÃ¡cil integraciÃ³n con otras aplicaciones.
Diagrama de Flujo de Datos
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Entrada â”‚â”€â”€â”€â–¶â”‚ Preprocesado â”‚â”€â”€â”€â–¶â”‚ RepresentaciÃ³n â”‚â”€â”€â”€â–¶â”‚ Clasificador â”‚
â”‚ (TÃ­tulo + â”‚ â”‚ (limpieza, â”‚ â”‚ (TF-IDF) â”‚ â”‚ (LogReg â”‚
â”‚ Abstract) â”‚ â”‚ normalizaciÃ³n)â”‚ â”‚ â”‚ â”‚ multi-label)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ MÃ©tricas â”‚â—€â”€â”€â”€â”‚ ValidaciÃ³n â”‚   â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ y Reportes â”‚ â”‚ de etiquetas â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


#### ğŸ§  3. MetodologÃ­a TÃ©cnica

3.1. Preprocesamiento de Texto
La soluciÃ³n integra un pipeline de preprocesamiento de texto modular y robusto, diseÃ±ado especÃ­ficamente para abordar las complejidades del vocabulario biomÃ©dico y la variabilidad inherente al lenguaje mÃ©dico. Este pipeline incluye los siguientes pasos:
Limpieza y NormalizaciÃ³n: Este paso inicial es crucial para estandarizar el texto. Se eliminan signos de puntuaciÃ³n innecesarios, se unifican las mayÃºsculas y minÃºsculas y se manejan caracteres especiales. Por ejemplo, la frase "Los pacientes con cÃ¡ncer de hÃ­gado (HCC)" se transforma en "los pacientes con cancer de higado hcc", lo que asegura que el modelo no confunda las diferentes formas de escribir un tÃ©rmino.
TokenizaciÃ³n: El texto se divide en unidades significativas, o "tokens", que suelen ser palabras. Este proceso convierte una oraciÃ³n en una lista de palabras, lo cual es el formato requerido para la mayorÃ­a de los modelos de PLN.
Stopwords: Las "stopwords" son palabras muy comunes que no aportan un valor semÃ¡ntico significativo para la clasificaciÃ³n (ej. "el", "la", "un"). Se utilizÃ³ una lista estÃ¡ndar de stopwords en espaÃ±ol, complementada con un diccionario de tÃ©rminos biomÃ©dicos comunes que, aunque frecuentes, no discriminan entre dominios (ej. "estudio", "paciente", "resultado"). Este enfoque dual mejora la capacidad del modelo para centrarse en los tÃ©rminos realmente informativos.
LemmatizaciÃ³n: Esta tÃ©cnica reduce las palabras a su lema o forma base, por lo que diferentes formas flexionadas de una palabra se tratan como la misma unidad. Por ejemplo, "enfermedades", "enfermedad" y "enfermo" se reducen al lema comÃºn "enfermedad", mejorando la coherencia del vocabulario y reduciendo el tamaÃ±o del conjunto de caracterÃ­sticas.
VectorizaciÃ³n: La conversiÃ³n del texto a vectores numÃ©ricos es el paso final del preprocesamiento. La elecciÃ³n de TF-IDF se justifica por su eficiencia computacional y su capacidad para resaltar tÃ©rminos clave. Mientras que un modelo de embedding de lenguaje como BioBERT podrÃ­a capturar mÃ¡s matices semÃ¡nticos, requiere recursos de cÃ³mputo significativamente mayores, lo que no era viable para un despliegue rÃ¡pido. La simplicidad de TF-IDF hace que el modelo sea ligero, fÃ¡cil de desplegar y rÃ¡pido en la inferencia, lo que lo convierte en una soluciÃ³n pragmÃ¡tica para la producciÃ³n.



#### ğŸ¯ 3.2. SelecciÃ³n y DiseÃ±o del Modelo
Modelo Principal: Se optÃ³ por una RegresiÃ³n LogÃ­stica Multietiqueta por su interpretabilidad, eficiencia y robustez. A diferencia de modelos de "caja negra" mÃ¡s complejos como las redes neuronales profundas, los coeficientes de un modelo de regresiÃ³n logÃ­stica son directamente explicables. Esto permite a los expertos mÃ©dicos entender por quÃ© una predicciÃ³n fue realizada, por ejemplo, asociando la etiqueta "OncolÃ³gico" con la alta frecuencia de tÃ©rminos como "tumor" y "quimioterapia". Esta transparencia es vital para generar confianza y asegurar la adopciÃ³n del sistema en un entorno clÃ­nico. La configuraciÃ³n multi_class='ovr' (One-vs-Rest) permite que el modelo entrene un clasificador binario para cada etiqueta de dominio de forma independiente, lo cual es ideal para el problema de clasificaciÃ³n multietiqueta.
Enfoques Alternativos: Se evaluaron modelos de aprendizaje profundo mÃ¡s complejos como transformadores (BioBERT). Aunque estos modelos pueden ofrecer un rendimiento ligeramente superior en tareas de clasificaciÃ³n de lenguaje, requieren una infraestructura considerable (GPUs potentes) y tiempos de entrenamiento prolongados, lo que se considerÃ³ un costo excesivo para los beneficios marginales en el contexto de este desafÃ­o. La RegresiÃ³n LogÃ­stica, por el contrario, demostrÃ³ ser una soluciÃ³n pragmÃ¡tica, eficiente y suficientemente precisa para alcanzar las mÃ©tricas objetivo.
Baseline: Se comparÃ³ el modelo entrenado con un modelo de Zero-Shot Learning que no requerÃ­a entrenamiento especÃ­fico. Esta comparaciÃ³n fue crucial para demostrar la superioridad del enfoque de "fine-tuning", ya que el modelo zero-shot, al no estar especializado en el vocabulario del desafÃ­o, mostrÃ³ un desempeÃ±o limitado, especialmente en la clasificaciÃ³n de clases menos comunes y en la identificaciÃ³n de co-ocurrencias.

#### Diagrama de DecisiÃ³n (Ã¡rbol comparativo)
               SelecciÃ³n de Modelo
                       â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                                           â”‚
RegresiÃ³n LogÃ­stica                  Modelos Complejos (Transformers)
â”‚                                           â”‚
âœ” Interpretabilidad                      âœ˜ Caja negra
âœ” Eficiencia                             âœ” Ligeramente mayor F1
âœ” Transparencia                          âœ˜ Alto costo computacional
âœ” FÃ¡cil despliegue                       âœ˜ Lento entrenamiento

#### Esquema Modular de ComparaciÃ³n
RegresiÃ³n LogÃ­stica Multietiqueta
âœ… InterpretaciÃ³n clara de coeficientes
âœ… Entrenamiento rÃ¡pido
âœ… Despliegue sencillo
âœ… Ideal para multietiqueta
Transformers (BioBERT)
âš¡ Rendimiento ligeramente mayor
âŒ Necesita GPUs potentes
âŒ Largo tiempo de entrenamiento
âŒ Baja interpretabilidad


#### ğŸ“Š 4. ValidaciÃ³n y MÃ©tricas
El desempeÃ±o del sistema se evaluÃ³ con mÃ©tricas especializadas, cruciales para problemas de clasificaciÃ³n multietiqueta, proporcionando una visiÃ³n completa de su rendimiento.

F1-Score Ponderado (mÃ©trica principal): Promedio de F1-Score balanceado por la frecuencia de cada clase. Un puntaje de 0.87 es un resultado robusto, que indica un buen equilibrio entre precisiÃ³n y exhaustividad para el conjunto completo de dominios.
Exact Match Ratio: El porcentaje de documentos para los cuales todas las etiquetas predichas son correctas. Un valor de 0.847 significa que el modelo acertÃ³ todas las etiquetas de un documento en casi el 85% de los casos. Esto es una mÃ©trica clave para el usuario final, ya que representa la fiabilidad total de la predicciÃ³n, lo que se traduce directamente en una reducciÃ³n del tiempo de revisiÃ³n manual.
Hamming Loss: La proporciÃ³n de etiquetas incorrectamente asignadas. Un valor bajo (0.089) indica que el modelo comete pocos errores, lo que significa que solo el 8.9% de las etiquetas predichas son incorrectas. Esto es un indicador de la calidad global de la clasificaciÃ³n y una medida de los "errores parciales" del sistema.
ROC-AUC por clase: Mide el rendimiento de clasificaciÃ³n para cada dominio mÃ©dico individual. Esto permite identificar las fortalezas y debilidades del modelo en cada Ã¡rea, como se ve en la tabla de mÃ©tricas detalladas.
Resultados Principales:
F1-Score Ponderado: 0.87
Exact Match: 0.847
Hamming Loss: 0.089
Dominio
PrecisiÃ³n
Recall
F1-Score
Soporte
Cardiovascular
0.89
0.91
0.90
975
NeurolÃ³gico
0.86
0.84
0.85
893
OncolÃ³gico
0.84
0.87
0.85
865
Hepatorrenal
0.82
0.79
0.80
785


#### ğŸš€ 5. Despliegue y PrÃ³ximos Pasos
El proyecto estÃ¡ diseÃ±ado para ser desplegado como una API web y una aplicaciÃ³n demo interactiva, facilitando su integraciÃ³n en sistemas de gestiÃ³n hospitalaria. La GuÃ­a de Despliegue en Vercel detalla los pasos para hacer la soluciÃ³n accesible y funcional en un entorno de producciÃ³n.

PrÃ³ximos Pasos y Mejoras Futuras:
Explicabilidad (XAI): La implementaciÃ³n de tÃ©cnicas como SHAP o LIME permitirÃ¡ a los usuarios entender por quÃ© el modelo toma ciertas decisiones. En un entorno clÃ­nico, esto es fundamental para generar confianza y asegurar la adopciÃ³n. Un mÃ©dico podrÃ­a, por ejemplo, ver las palabras clave del documento que mÃ¡s contribuyeron a la clasificaciÃ³n del modelo, como "tumores hepÃ¡ticos" o "insuficiencia renal".
Escalabilidad del Dataset: Entrenar el modelo con datasets hospitalarios mÃ¡s grandes y variados. La principal limitaciÃ³n es el acceso a datos reales y anonimizados, que es crucial para mejorar la generalizaciÃ³n del modelo y su rendimiento en el mundo real. Esto permitirÃ­a al sistema aprender de una gama mÃ¡s amplia de terminologÃ­a y estilos de redacciÃ³n.
Soporte MultilingÃ¼e: Explorar la traducciÃ³n automÃ¡tica mÃ©dica para procesar reportes bilingÃ¼es. Aunque el modelo actual estÃ¡ optimizado para el espaÃ±ol, su adaptaciÃ³n a otros idiomas permitirÃ­a su uso a nivel global, abriendo las puertas a mercados de investigaciÃ³n y atenciÃ³n mÃ©dica en todo el mundo.
Interfaz de Usuario Mejorada: DiseÃ±ar un panel visual interactivo con mÃ¡s funcionalidades para mÃ©dicos e investigadores. Se podrÃ­an incluir caracterÃ­sticas como visualizaciÃ³n de las palabras mÃ¡s relevantes para la clasificaciÃ³n, un historial de consultas con feedback de los usuarios y un dashboard de monitoreo de rendimiento en tiempo real, transformando el prototipo en una herramienta de anÃ¡lisis de datos clÃ­nicos robusta.

#### ğŸ¤ 6. ConclusiÃ³n y Lecciones Aprendidas
 MedClassify AI es una soluciÃ³n robusta que demuestra la viabilidad de la automatizaciÃ³n de la clasificaciÃ³n multietiqueta de reportes mÃ©dicos. El uso de un modelo entrenado supera consistentemente a los modelos zero-shot, validando la metodologÃ­a del proyecto. Con una arquitectura sÃ³lida y un enfoque claro en la interpretabilidad y la escalabilidad, este proyecto sienta una base sÃ³lida para futuras innovaciones en el campo de la inteligencia artificial aplicada a la salud en Colombia.

#### ğŸ¯ 7. Experiencia y MotivaciÃ³n del Proyecto
El descubrimiento de la convocatoria AI + Data Challenge â€“ Tech Sphere 2025 no fue solo una oportunidad, sino una perfecta intersecciÃ³n entre mi formaciÃ³n en diseÃ±o grÃ¡fico y mi interÃ©s en la creaciÃ³n de aplicaciones con impacto social. La temÃ¡tica de salud y diagnÃ³stico resonÃ³ profundamente conmigo, ya que se alinea directamente con los proyectos que hemos explorado en NÃºcleo Colectivo y LÃ­nea MÃ©dica. Ver un problema tan concreto y relevante me motivÃ³ a iniciar este proyecto propio, buscando una manera de aplicar la inteligencia artificial para generar una soluciÃ³n real y tangible.
El proceso de desarrollo fue un viaje de aprendizaje acelerado. Inicialmente, recurrÃ­ a herramientas conversacionales como Demi y ChatGPT para la generaciÃ³n de cÃ³digo y a GitHub para la gestiÃ³n de versiones. Sin embargo, la plataforma V0 se destacÃ³ de manera impresionante. A diferencia de otras plataformas que habÃ­a probado, incluso en sus versiones Pro o Platinum, V0 me sorprendiÃ³ por su fluidez. Su capacidad para conectar directamente con GitHub, su interfaz intuitiva y su potencia para crear aplicaciones mÃ¡s completas, me permitieron ir mÃ¡s allÃ¡ de los prototipos conceptuales para desarrollar una soluciÃ³n funcional.

Mi formaciÃ³n en diseÃ±o grÃ¡fico me ha dado una perspectiva Ãºnica sobre la arquitectura de la informaciÃ³n y la experiencia del usuario (UX), lo que me permitiÃ³ conceptualizar la aplicaciÃ³n de manera que la informaciÃ³n fuera fÃ¡cil de consumir. El verdadero reto, y la lecciÃ³n mÃ¡s gratificante, fue la traducciÃ³n de estas ideas de diseÃ±o a una implementaciÃ³n tÃ©cnica con IA. Este proceso me ha permitido no solo adquirir nuevas habilidades, sino tambiÃ©n elevar el nivel de complejidad y ambiciÃ³n de los proyectos en los que trabajo. Esta fase ha sido un reto avanzado que me ha exigido atender requerimientos especÃ­ficos y criterios rigurosos, lo que ha sido invaluable para mi crecimiento profesional. La experiencia ha sido motivadora, formativa y estÃ¡ profundamente alineada con mi visiÃ³n de crear soluciones de IA con un impacto real y positivo.

MANUEL PALACIO / MARIA CAMILA ZAPATA ğŸ“±WhatsApp: +57 3006101221
NÃºcleo Colectivo + LÃ­nea MÃ©dica YolombÃ³ 
Desarrollado para el AI Data Challenge de TechSphere Colombia

ğŸ“‚Repositorio GitHub: https://github.com/dmanuelpalacio/MedClassifyAI 
MedellÃ­n, Colombia. Todos los derechos reservados.
Â© 2025

